{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pythainlp import word_tokenize\n",
    "from tqdm import tqdm_notebook\n",
    "import re\n",
    "import emoji\n",
    "\n",
    "#viz\n",
    "from plotnine import *\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from collections import Counter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import string\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_url(text):\n",
    "    URL_PATTERN = r\"\"\"(?i)\\b((?:https?:(?:/{1,3}|[a-z0-9%])|[a-z0-9.\\-]+[.](?:com|net|org|edu|gov|mil|aero|asia|biz|cat|coop|info|int|jobs|mobi|museum|name|post|pro|tel|travel|xxx|ac|ad|ae|af|ag|ai|al|am|an|ao|aq|ar|as|at|au|aw|ax|az|ba|bb|bd|be|bf|bg|bh|bi|bj|bm|bn|bo|br|bs|bt|bv|bw|by|bz|ca|cc|cd|cf|cg|ch|ci|ck|cl|cm|cn|co|cr|cs|cu|cv|cx|cy|cz|dd|de|dj|dk|dm|do|dz|ec|ee|eg|eh|er|es|et|eu|fi|fj|fk|fm|fo|fr|ga|gb|gd|ge|gf|gg|gh|gi|gl|gm|gn|gp|gq|gr|gs|gt|gu|gw|gy|hk|hm|hn|hr|ht|hu|id|ie|il|im|in|io|iq|ir|is|it|je|jm|jo|jp|ke|kg|kh|ki|km|kn|kp|kr|kw|ky|kz|la|lb|lc|li|lk|lr|ls|lt|lu|lv|ly|ma|mc|md|me|mg|mh|mk|ml|mm|mn|mo|mp|mq|mr|ms|mt|mu|mv|mw|mx|my|mz|na|nc|ne|nf|ng|ni|nl|no|np|nr|nu|nz|om|pa|pe|pf|pg|ph|pk|pl|pm|pn|pr|ps|pt|pw|py|qa|re|ro|rs|ru|rw|sa|sb|sc|sd|se|sg|sh|si|sj|Ja|sk|sl|sm|sn|so|sr|ss|st|su|sv|sx|sy|sz|tc|td|tf|tg|th|tj|tk|tl|tm|tn|to|tp|tr|tt|tv|tw|tz|ua|ug|uk|us|uy|uz|va|vc|ve|vg|vi|vn|vu|wf|ws|ye|yt|yu|za|zm|zw)/)(?:[^\\s()<>{}\\[\\]]+|\\([^\\s()]*?\\([^\\s()]+\\)[^\\s()]*?\\)|\\([^\\s]+?\\))+(?:\\([^\\s()]*?\\([^\\s()]+\\)[^\\s()]*?\\)|\\([^\\s]+?\\)|[^\\s`!()\\[\\]{};:'\".,<>?¬´¬ª‚Äú‚Äù‚Äò‚Äô])|(?:(?<!@)[a-z0-9]+(?:[.\\-][a-z0-9]+)*[.](?:com|net|org|edu|gov|mil|aero|asia|biz|cat|coop|info|int|jobs|mobi|museum|name|post|pro|tel|travel|xxx|ac|ad|ae|af|ag|ai|al|am|an|ao|aq|ar|as|at|au|aw|ax|az|ba|bb|bd|be|bf|bg|bh|bi|bj|bm|bn|bo|br|bs|bt|bv|bw|by|bz|ca|cc|cd|cf|cg|ch|ci|ck|cl|cm|cn|co|cr|cs|cu|cv|cx|cy|cz|dd|de|dj|dk|dm|do|dz|ec|ee|eg|eh|er|es|et|eu|fi|fj|fk|fm|fo|fr|ga|gb|gd|ge|gf|gg|gh|gi|gl|gm|gn|gp|gq|gr|gs|gt|gu|gw|gy|hk|hm|hn|hr|ht|hu|id|ie|il|im|in|io|iq|ir|is|it|je|jm|jo|jp|ke|kg|kh|ki|km|kn|kp|kr|kw|ky|kz|la|lb|lc|li|lk|lr|ls|lt|lu|lv|ly|ma|mc|md|me|mg|mh|mk|ml|mm|mn|mo|mp|mq|mr|ms|mt|mu|mv|mw|mx|my|mz|na|nc|ne|nf|ng|ni|nl|no|np|nr|nu|nz|om|pa|pe|pf|pg|ph|pk|pl|pm|pn|pr|ps|pt|pw|py|qa|re|ro|rs|ru|rw|sa|sb|sc|sd|se|sg|sh|si|sj|Ja|sk|sl|sm|sn|so|sr|ss|st|su|sv|sx|sy|sz|tc|td|tf|tg|th|tj|tk|tl|tm|tn|to|tp|tr|tt|tv|tw|tz|ua|ug|uk|us|uy|uz|va|vc|ve|vg|vi|vn|vu|wf|ws|ye|yt|yu|za|zm|zw)\\b/?(?!@)))\"\"\"\n",
    "    return re.sub(URL_PATTERN, 'xxurl', text)\n",
    "\n",
    "def replace_rep(text):\n",
    "    def _replace_rep(m):\n",
    "        c,cc = m.groups()\n",
    "        return f'{c}xxrep'\n",
    "    re_rep = re.compile(r'(\\S)(\\1{2,})')\n",
    "    return re_rep.sub(_replace_rep, text)\n",
    "\n",
    "def ungroup_emoji(toks):\n",
    "    res = []\n",
    "    for tok in toks:\n",
    "        if emoji.emoji_count(tok) == len(tok):\n",
    "            for char in tok:\n",
    "                res.append(char)\n",
    "        else:\n",
    "            res.append(tok)\n",
    "    return res\n",
    "\n",
    "def process_text(text):\n",
    "    #pre rules\n",
    "    res = text.lower().strip()\n",
    "    res = replace_url(res)\n",
    "    res = replace_rep(res)\n",
    "    \n",
    "    #tokenize\n",
    "    res = [word for word in word_tokenize(res) if word and not re.search(pattern=r\"\\s+\", string=word)]\n",
    "    \n",
    "    #post rules\n",
    "    res = ungroup_emoji(res)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24063, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('train.txt') as f:\n",
    "    texts = [line.strip() for line in f.readlines()]\n",
    "f.close()\n",
    "\n",
    "with open('train_label.txt') as f:\n",
    "    categories = [line.strip() for line in f.readlines()]\n",
    "f.close()\n",
    "\n",
    "all_df = pd.DataFrame({'category':categories, 'texts':texts})\n",
    "all_df.to_csv('all_df.csv',index=False)\n",
    "all_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2674, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('test.txt') as f:\n",
    "    texts = [line.strip() for line in f.readlines()]\n",
    "f.close()\n",
    "\n",
    "test_df = pd.DataFrame({'category':'test', 'texts':texts})\n",
    "test_df.to_csv('test_df.csv',index=False)\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.read_csv('all_df.csv')\n",
    "test_df = pd.read_csv('test_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neu</td>\n",
       "      <td>‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÄ‡∏£‡∏≤‡∏ú‡∏•‡∏¥‡∏ï‡πÅ‡∏•‡∏∞‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å‡∏¢‡∏≤‡∏™‡∏π‡∏ö‡πÄ‡∏¢‡∏≠‡∏∞‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡πÇ‡∏•‡∏Å‡∏à‡∏¥‡∏á‡∏õ‡πà‡∏≤‡∏ß‡∏Ñ‡∏±‡∏ö</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neu</td>\n",
       "      <td>‡∏Ñ‡∏∞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neg</td>\n",
       "      <td>‡∏≠‡∏¥‡πÄ‡∏´‡∏µ‡πâ‡∏¢‡∏≠‡∏≠‡∏°‡∏ó‡∏≥‡∏Å‡∏π‡∏≠‡∏¢‡∏≤‡∏Å‡∏Å‡∏¥‡∏ô‡πÄ‡∏≠‡πá‡∏°‡πÄ‡∏Ñ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neu</td>\n",
       "      <td>üòÖüòÖüòÖ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neu</td>\n",
       "      <td>‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏ß‡∏±‡∏ô‡∏û‡∏∏‡∏ò ‡πÅ‡∏ô‡∏ô ‡∏≠‡∏∞‡πÑ‡∏£‡∏ô‡∏∞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24058</th>\n",
       "      <td>neg</td>\n",
       "      <td>‡πÅ‡∏°‡πà‡∏á‡∏Ñ‡∏ß‡∏≤‡∏¢‡∏•‡πâ‡∏ß‡∏ô‡∏ô‡∏ô</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24059</th>\n",
       "      <td>neg</td>\n",
       "      <td>‡∏î‡∏≠‡∏¢‡∏™‡∏∏‡πÄ‡∏ó‡∏û‡∏ô‡πâ‡∏≠‡∏á‡∏á ‡πÑ‡∏õ‡∏´‡∏°‡∏î‡πÅ‡∏•‡πâ‡∏ß‡∏ß‡∏ß‡∏ß #pm25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24060</th>\n",
       "      <td>neg</td>\n",
       "      <td>‡∏Ñ‡πà‡∏≤‡∏ä‡∏∏‡∏î‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡πÅ‡∏û‡∏á‡∏Å‡∏ß‡πà‡∏≤‡∏™‡πà‡∏ß‡∏ô‡∏•‡∏î</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24061</th>\n",
       "      <td>neu</td>\n",
       "      <td>‡∏£‡∏±‡∏ê‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏Ñ‡πà‡∏†‡∏≤‡∏©‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24062</th>\n",
       "      <td>neu</td>\n",
       "      <td>‚Ñ¢ ‡πÑ‡∏î‡πâ‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏£‡∏∏‡πà‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏á‡πÅ‡∏•‡πâ‡∏ß ‡∏°‡∏≤‡∏î‡∏π‡∏Å‡∏±‡∏ô‡∏™‡∏¥‡∏ß...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24063 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      category                                              texts\n",
       "0          neu  ‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÄ‡∏£‡∏≤‡∏ú‡∏•‡∏¥‡∏ï‡πÅ‡∏•‡∏∞‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å‡∏¢‡∏≤‡∏™‡∏π‡∏ö‡πÄ‡∏¢‡∏≠‡∏∞‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡πÇ‡∏•‡∏Å‡∏à‡∏¥‡∏á‡∏õ‡πà‡∏≤‡∏ß‡∏Ñ‡∏±‡∏ö\n",
       "1          neu                                                 ‡∏Ñ‡∏∞\n",
       "2          neg                        ‡∏≠‡∏¥‡πÄ‡∏´‡∏µ‡πâ‡∏¢‡∏≠‡∏≠‡∏°‡∏ó‡∏≥‡∏Å‡∏π‡∏≠‡∏¢‡∏≤‡∏Å‡∏Å‡∏¥‡∏ô‡πÄ‡∏≠‡πá‡∏°‡πÄ‡∏Ñ\n",
       "3          neu                                                üòÖüòÖüòÖ\n",
       "4          neu                            ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏ß‡∏±‡∏ô‡∏û‡∏∏‡∏ò ‡πÅ‡∏ô‡∏ô ‡∏≠‡∏∞‡πÑ‡∏£‡∏ô‡∏∞\n",
       "...        ...                                                ...\n",
       "24058      neg                                     ‡πÅ‡∏°‡πà‡∏á‡∏Ñ‡∏ß‡∏≤‡∏¢‡∏•‡πâ‡∏ß‡∏ô‡∏ô‡∏ô\n",
       "24059      neg                   ‡∏î‡∏≠‡∏¢‡∏™‡∏∏‡πÄ‡∏ó‡∏û‡∏ô‡πâ‡∏≠‡∏á‡∏á ‡πÑ‡∏õ‡∏´‡∏°‡∏î‡πÅ‡∏•‡πâ‡∏ß‡∏ß‡∏ß‡∏ß #pm25\n",
       "24060      neg                           ‡∏Ñ‡πà‡∏≤‡∏ä‡∏∏‡∏î‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡πÅ‡∏û‡∏á‡∏Å‡∏ß‡πà‡∏≤‡∏™‡πà‡∏ß‡∏ô‡∏•‡∏î\n",
       "24061      neu                              ‡∏£‡∏±‡∏ê‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏Ñ‡πà‡∏†‡∏≤‡∏©‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö\n",
       "24062      neu  ‚Ñ¢ ‡πÑ‡∏î‡πâ‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏£‡∏∏‡πà‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏á‡πÅ‡∏•‡πâ‡∏ß ‡∏°‡∏≤‡∏î‡∏π‡∏Å‡∏±‡∏ô‡∏™‡∏¥‡∏ß...\n",
       "\n",
       "[24063 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df['processed'] = all_df.texts.map(lambda x: '|'.join(process_text(x)))\n",
    "all_df['wc'] = all_df.processed.map(lambda x: len(x.split('|')))\n",
    "\n",
    "test_df['processed'] = test_df.texts.map(lambda x: '|'.join(process_text(x)))\n",
    "test_df['wc'] = test_df.processed.map(lambda x: len(x.split('|')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neu    0.544612\n",
       "neg    0.255164\n",
       "pos    0.178698\n",
       "q      0.021527\n",
       "Name: category, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.category.value_counts() / all_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_numbering = {'neu':0, 'neg':1, 'pos':2, 'q':3}\n",
    "all_df['labels'] = all_df['category'].apply(lambda x: zero_numbering[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>texts</th>\n",
       "      <th>processed</th>\n",
       "      <th>wc</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neu</td>\n",
       "      <td>‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÄ‡∏£‡∏≤‡∏ú‡∏•‡∏¥‡∏ï‡πÅ‡∏•‡∏∞‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å‡∏¢‡∏≤‡∏™‡∏π‡∏ö‡πÄ‡∏¢‡∏≠‡∏∞‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡πÇ‡∏•‡∏Å‡∏à‡∏¥‡∏á‡∏õ‡πà‡∏≤‡∏ß‡∏Ñ‡∏±‡∏ö</td>\n",
       "      <td>‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®|‡πÄ‡∏£‡∏≤|‡∏ú‡∏•‡∏¥‡∏ï|‡πÅ‡∏•‡∏∞|‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å|‡∏¢‡∏≤‡∏™‡∏π‡∏ö|‡πÄ‡∏¢‡∏≠‡∏∞|‡∏™‡∏∏‡∏î|‡πÉ‡∏ô|‡πÇ...</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neu</td>\n",
       "      <td>‡∏Ñ‡∏∞</td>\n",
       "      <td>‡∏Ñ‡∏∞</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neg</td>\n",
       "      <td>‡∏≠‡∏¥‡πÄ‡∏´‡∏µ‡πâ‡∏¢‡∏≠‡∏≠‡∏°‡∏ó‡∏≥‡∏Å‡∏π‡∏≠‡∏¢‡∏≤‡∏Å‡∏Å‡∏¥‡∏ô‡πÄ‡∏≠‡πá‡∏°‡πÄ‡∏Ñ</td>\n",
       "      <td>‡∏≠‡∏¥|‡πÄ‡∏´‡∏µ‡πâ‡∏¢|‡∏≠‡∏≠‡∏°|‡∏ó‡∏≥|‡∏Å‡∏π|‡∏≠‡∏¢‡∏≤‡∏Å|‡∏Å‡∏¥‡∏ô|‡πÄ‡∏≠‡πá‡∏°|‡πÄ‡∏Ñ</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neu</td>\n",
       "      <td>üòÖüòÖüòÖ</td>\n",
       "      <td>üòÖ|xxrep</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neu</td>\n",
       "      <td>‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏ß‡∏±‡∏ô‡∏û‡∏∏‡∏ò ‡πÅ‡∏ô‡∏ô ‡∏≠‡∏∞‡πÑ‡∏£‡∏ô‡∏∞</td>\n",
       "      <td>‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ|‡∏ß‡∏±‡∏ô|‡∏û‡∏∏‡∏ò|‡πÅ‡∏ô‡∏ô|‡∏≠‡∏∞‡πÑ‡∏£|‡∏ô‡∏∞</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category                                              texts  \\\n",
       "0      neu  ‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÄ‡∏£‡∏≤‡∏ú‡∏•‡∏¥‡∏ï‡πÅ‡∏•‡∏∞‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å‡∏¢‡∏≤‡∏™‡∏π‡∏ö‡πÄ‡∏¢‡∏≠‡∏∞‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡πÇ‡∏•‡∏Å‡∏à‡∏¥‡∏á‡∏õ‡πà‡∏≤‡∏ß‡∏Ñ‡∏±‡∏ö   \n",
       "1      neu                                                 ‡∏Ñ‡∏∞   \n",
       "2      neg                        ‡∏≠‡∏¥‡πÄ‡∏´‡∏µ‡πâ‡∏¢‡∏≠‡∏≠‡∏°‡∏ó‡∏≥‡∏Å‡∏π‡∏≠‡∏¢‡∏≤‡∏Å‡∏Å‡∏¥‡∏ô‡πÄ‡∏≠‡πá‡∏°‡πÄ‡∏Ñ   \n",
       "3      neu                                                üòÖüòÖüòÖ   \n",
       "4      neu                            ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏ß‡∏±‡∏ô‡∏û‡∏∏‡∏ò ‡πÅ‡∏ô‡∏ô ‡∏≠‡∏∞‡πÑ‡∏£‡∏ô‡∏∞   \n",
       "\n",
       "                                           processed  wc  labels  \n",
       "0  ‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®|‡πÄ‡∏£‡∏≤|‡∏ú‡∏•‡∏¥‡∏ï|‡πÅ‡∏•‡∏∞|‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å|‡∏¢‡∏≤‡∏™‡∏π‡∏ö|‡πÄ‡∏¢‡∏≠‡∏∞|‡∏™‡∏∏‡∏î|‡πÉ‡∏ô|‡πÇ...  13       0  \n",
       "1                                                 ‡∏Ñ‡∏∞   1       0  \n",
       "2                ‡∏≠‡∏¥|‡πÄ‡∏´‡∏µ‡πâ‡∏¢|‡∏≠‡∏≠‡∏°|‡∏ó‡∏≥|‡∏Å‡∏π|‡∏≠‡∏¢‡∏≤‡∏Å|‡∏Å‡∏¥‡∏ô|‡πÄ‡∏≠‡πá‡∏°|‡πÄ‡∏Ñ   9       1  \n",
       "3                                            üòÖ|xxrep   2       0  \n",
       "4                         ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ|‡∏ß‡∏±‡∏ô|‡∏û‡∏∏‡∏ò|‡πÅ‡∏ô‡∏ô|‡∏≠‡∏∞‡πÑ‡∏£|‡∏ô‡∏∞   6       0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count number of occurences of each word\n",
    "counts = Counter()\n",
    "for index, row in all_df.iterrows():\n",
    "    counts.update(row['processed'].split('|'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_words before: 26723\n",
      "num_words after: 14937\n"
     ]
    }
   ],
   "source": [
    "#deleting infrequent words\n",
    "print(\"num_words before:\",len(counts.keys()))\n",
    "for word in list(counts):\n",
    "    if counts[word] < 2:\n",
    "        del counts[word]\n",
    "print(\"num_words after:\",len(counts.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating vocabulary\n",
    "vocab2index = {\"\":0, \"UNK\":1}\n",
    "words = [\"\", \"UNK\"]\n",
    "for word in counts:\n",
    "    vocab2index[word] = len(words)\n",
    "    words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentence(text, vocab2index, N=100):\n",
    "    tokenized = text.split('|')\n",
    "    encoded = np.zeros(N, dtype=int)\n",
    "    enc1 = np.array([vocab2index.get(word, vocab2index[\"UNK\"]) for word in tokenized])\n",
    "    length = min(N, len(enc1))\n",
    "    encoded[:length] = enc1[:length]\n",
    "    return encoded, length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>texts</th>\n",
       "      <th>processed</th>\n",
       "      <th>wc</th>\n",
       "      <th>labels</th>\n",
       "      <th>encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neu</td>\n",
       "      <td>‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÄ‡∏£‡∏≤‡∏ú‡∏•‡∏¥‡∏ï‡πÅ‡∏•‡∏∞‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å‡∏¢‡∏≤‡∏™‡∏π‡∏ö‡πÄ‡∏¢‡∏≠‡∏∞‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡πÇ‡∏•‡∏Å‡∏à‡∏¥‡∏á‡∏õ‡πà‡∏≤‡∏ß‡∏Ñ‡∏±‡∏ö</td>\n",
       "      <td>‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®|‡πÄ‡∏£‡∏≤|‡∏ú‡∏•‡∏¥‡∏ï|‡πÅ‡∏•‡∏∞|‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å|‡∏¢‡∏≤‡∏™‡∏π‡∏ö|‡πÄ‡∏¢‡∏≠‡∏∞|‡∏™‡∏∏‡∏î|‡πÉ‡∏ô|‡πÇ...</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>[[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neu</td>\n",
       "      <td>‡∏Ñ‡∏∞</td>\n",
       "      <td>‡∏Ñ‡∏∞</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[[15, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neg</td>\n",
       "      <td>‡∏≠‡∏¥‡πÄ‡∏´‡∏µ‡πâ‡∏¢‡∏≠‡∏≠‡∏°‡∏ó‡∏≥‡∏Å‡∏π‡∏≠‡∏¢‡∏≤‡∏Å‡∏Å‡∏¥‡∏ô‡πÄ‡∏≠‡πá‡∏°‡πÄ‡∏Ñ</td>\n",
       "      <td>‡∏≠‡∏¥|‡πÄ‡∏´‡∏µ‡πâ‡∏¢|‡∏≠‡∏≠‡∏°|‡∏ó‡∏≥|‡∏Å‡∏π|‡∏≠‡∏¢‡∏≤‡∏Å|‡∏Å‡∏¥‡∏ô|‡πÄ‡∏≠‡πá‡∏°|‡πÄ‡∏Ñ</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>[[16, 17, 18, 19, 20, 21, 22, 23, 24, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neu</td>\n",
       "      <td>üòÖüòÖüòÖ</td>\n",
       "      <td>üòÖ|xxrep</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[[25, 26, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neu</td>\n",
       "      <td>‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏ß‡∏±‡∏ô‡∏û‡∏∏‡∏ò ‡πÅ‡∏ô‡∏ô ‡∏≠‡∏∞‡πÑ‡∏£‡∏ô‡∏∞</td>\n",
       "      <td>‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ|‡∏ß‡∏±‡∏ô|‡∏û‡∏∏‡∏ò|‡πÅ‡∏ô‡∏ô|‡∏≠‡∏∞‡πÑ‡∏£|‡∏ô‡∏∞</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[[27, 28, 29, 30, 31, 32, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category                                              texts  \\\n",
       "0      neu  ‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÄ‡∏£‡∏≤‡∏ú‡∏•‡∏¥‡∏ï‡πÅ‡∏•‡∏∞‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å‡∏¢‡∏≤‡∏™‡∏π‡∏ö‡πÄ‡∏¢‡∏≠‡∏∞‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡πÇ‡∏•‡∏Å‡∏à‡∏¥‡∏á‡∏õ‡πà‡∏≤‡∏ß‡∏Ñ‡∏±‡∏ö   \n",
       "1      neu                                                 ‡∏Ñ‡∏∞   \n",
       "2      neg                        ‡∏≠‡∏¥‡πÄ‡∏´‡∏µ‡πâ‡∏¢‡∏≠‡∏≠‡∏°‡∏ó‡∏≥‡∏Å‡∏π‡∏≠‡∏¢‡∏≤‡∏Å‡∏Å‡∏¥‡∏ô‡πÄ‡∏≠‡πá‡∏°‡πÄ‡∏Ñ   \n",
       "3      neu                                                üòÖüòÖüòÖ   \n",
       "4      neu                            ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏ß‡∏±‡∏ô‡∏û‡∏∏‡∏ò ‡πÅ‡∏ô‡∏ô ‡∏≠‡∏∞‡πÑ‡∏£‡∏ô‡∏∞   \n",
       "\n",
       "                                           processed  wc  labels  \\\n",
       "0  ‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®|‡πÄ‡∏£‡∏≤|‡∏ú‡∏•‡∏¥‡∏ï|‡πÅ‡∏•‡∏∞|‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å|‡∏¢‡∏≤‡∏™‡∏π‡∏ö|‡πÄ‡∏¢‡∏≠‡∏∞|‡∏™‡∏∏‡∏î|‡πÉ‡∏ô|‡πÇ...  13       0   \n",
       "1                                                 ‡∏Ñ‡∏∞   1       0   \n",
       "2                ‡∏≠‡∏¥|‡πÄ‡∏´‡∏µ‡πâ‡∏¢|‡∏≠‡∏≠‡∏°|‡∏ó‡∏≥|‡∏Å‡∏π|‡∏≠‡∏¢‡∏≤‡∏Å|‡∏Å‡∏¥‡∏ô|‡πÄ‡∏≠‡πá‡∏°|‡πÄ‡∏Ñ   9       1   \n",
       "3                                            üòÖ|xxrep   2       0   \n",
       "4                         ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ|‡∏ß‡∏±‡∏ô|‡∏û‡∏∏‡∏ò|‡πÅ‡∏ô‡∏ô|‡∏≠‡∏∞‡πÑ‡∏£|‡∏ô‡∏∞   6       0   \n",
       "\n",
       "                                             encoded  \n",
       "0  [[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, ...  \n",
       "1  [[15, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...  \n",
       "2  [[16, 17, 18, 19, 20, 21, 22, 23, 24, 0, 0, 0,...  \n",
       "3  [[25, 26, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [[27, 28, 29, 30, 31, 32, 0, 0, 0, 0, 0, 0, 0,...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df['encoded'] = all_df['processed'].apply(lambda x: np.array(encode_sentence(x,vocab2index )))\n",
    "all_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, valid_df = train_test_split(all_df, test_size=0.15, random_state=42)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "valid_df = valid_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df['encoded']\n",
    "X_valid = valid_df['encoded']\n",
    "y_train = train_df['labels']\n",
    "y_valid = valid_df['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.y = Y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.from_numpy(self.X[idx][0].astype(np.int32)), self.y[idx], self.X[idx][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = SentimentDataset(X_train, y_train)\n",
    "valid_ds = SentimentDataset(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, epochs=50, lr=0.001):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optimizer = torch.optim.Adam(parameters, lr=lr)\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        sum_loss = 0.0\n",
    "        total = 0\n",
    "        for x, y, l in train_dl:\n",
    "            x = x.long()\n",
    "            y = y.long()\n",
    "            y_pred = model(x, l)\n",
    "            optimizer.zero_grad()\n",
    "            loss = F.cross_entropy(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            sum_loss += loss.item()*y.shape[0]\n",
    "            total += y.shape[0]\n",
    "        val_loss, val_acc, val_rmse = validation_metrics(model, val_dl)\n",
    "        if i % 2 == 1:\n",
    "            print(\"train loss %.3f, val loss %.3f, val accuracy %.3f, and val rmse %.3f\" % (sum_loss/total, val_loss, val_acc, val_rmse))\n",
    "\n",
    "def validation_metrics (model, valid_dl):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    sum_loss = 0.0\n",
    "    sum_rmse = 0.0\n",
    "    for x, y, l in valid_dl:\n",
    "        x = x.long()\n",
    "        y = y.long()\n",
    "        y_hat = model(x, l)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        pred = torch.max(y_hat, 1)[1]\n",
    "        correct += (pred == y).float().sum()\n",
    "        total += y.shape[0]\n",
    "        sum_loss += loss.item()*y.shape[0]\n",
    "        sum_rmse += np.sqrt(mean_squared_error(pred, y.unsqueeze(-1)))*y.shape[0]\n",
    "    return sum_loss/total, correct/total, sum_rmse/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_fixed_len(torch.nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim) :\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, 5)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x, l):\n",
    "        x = self.embeddings(x)\n",
    "        x = self.dropout(x)\n",
    "        lstm_out, (ht, ct) = self.lstm(x)\n",
    "        return self.linear(ht[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2048\n",
    "vocab_size = len(words)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_dl = DataLoader(valid_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fixed =  LSTM_fixed_len(vocab_size, 100, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 1.085, val loss 1.074, val accuracy 0.542, and val rmse 1.075\n",
      "train loss 1.065, val loss 1.067, val accuracy 0.541, and val rmse 1.076\n",
      "train loss 1.056, val loss 1.062, val accuracy 0.541, and val rmse 1.077\n",
      "train loss 1.057, val loss 1.065, val accuracy 0.541, and val rmse 1.076\n",
      "train loss 1.052, val loss 1.066, val accuracy 0.541, and val rmse 1.075\n",
      "train loss 1.023, val loss 1.020, val accuracy 0.541, and val rmse 1.075\n",
      "train loss 0.902, val loss 0.924, val accuracy 0.635, and val rmse 0.975\n",
      "train loss 0.804, val loss 0.917, val accuracy 0.655, and val rmse 0.970\n",
      "train loss 0.745, val loss 0.932, val accuracy 0.650, and val rmse 0.970\n",
      "train loss 0.684, val loss 0.967, val accuracy 0.652, and val rmse 0.972\n",
      "train loss 0.635, val loss 0.965, val accuracy 0.626, and val rmse 1.009\n",
      "train loss 0.598, val loss 0.979, val accuracy 0.630, and val rmse 1.000\n",
      "train loss 0.566, val loss 1.000, val accuracy 0.615, and val rmse 1.022\n",
      "train loss 0.537, val loss 1.009, val accuracy 0.627, and val rmse 1.027\n",
      "train loss 0.511, val loss 1.051, val accuracy 0.605, and val rmse 1.039\n",
      "train loss 0.480, val loss 1.019, val accuracy 0.615, and val rmse 1.037\n",
      "train loss 0.459, val loss 1.063, val accuracy 0.609, and val rmse 1.044\n",
      "train loss 0.439, val loss 1.095, val accuracy 0.629, and val rmse 1.014\n",
      "train loss 0.423, val loss 1.087, val accuracy 0.622, and val rmse 1.033\n",
      "train loss 0.401, val loss 1.086, val accuracy 0.632, and val rmse 1.015\n",
      "train loss 0.382, val loss 1.131, val accuracy 0.634, and val rmse 1.032\n",
      "train loss 0.369, val loss 1.103, val accuracy 0.644, and val rmse 0.999\n",
      "train loss 0.356, val loss 1.111, val accuracy 0.633, and val rmse 1.020\n",
      "train loss 0.334, val loss 1.144, val accuracy 0.632, and val rmse 1.030\n",
      "train loss 0.330, val loss 1.141, val accuracy 0.629, and val rmse 1.024\n"
     ]
    }
   ],
   "source": [
    "train_model(model_fixed, epochs=50, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.470, val loss 1.151, val accuracy 0.628, and val rmse 1.030\n",
      "train loss 0.438, val loss 1.199, val accuracy 0.630, and val rmse 1.027\n",
      "train loss 0.428, val loss 1.199, val accuracy 0.635, and val rmse 1.015\n",
      "train loss 0.419, val loss 1.202, val accuracy 0.637, and val rmse 1.008\n",
      "train loss 0.396, val loss 1.263, val accuracy 0.638, and val rmse 1.001\n",
      "train loss 0.391, val loss 1.247, val accuracy 0.635, and val rmse 1.011\n",
      "train loss 0.382, val loss 1.257, val accuracy 0.637, and val rmse 0.998\n",
      "train loss 0.368, val loss 1.266, val accuracy 0.637, and val rmse 1.006\n",
      "train loss 0.365, val loss 1.280, val accuracy 0.641, and val rmse 1.001\n",
      "train loss 0.358, val loss 1.267, val accuracy 0.636, and val rmse 1.003\n",
      "train loss 0.344, val loss 1.335, val accuracy 0.640, and val rmse 1.002\n",
      "train loss 0.337, val loss 1.328, val accuracy 0.634, and val rmse 1.015\n",
      "train loss 0.334, val loss 1.315, val accuracy 0.635, and val rmse 1.014\n",
      "train loss 0.325, val loss 1.348, val accuracy 0.639, and val rmse 1.005\n",
      "train loss 0.317, val loss 1.342, val accuracy 0.642, and val rmse 0.994\n",
      "train loss 0.314, val loss 1.338, val accuracy 0.646, and val rmse 0.988\n",
      "train loss 0.301, val loss 1.358, val accuracy 0.642, and val rmse 0.997\n",
      "train loss 0.294, val loss 1.361, val accuracy 0.643, and val rmse 0.985\n",
      "train loss 0.283, val loss 1.347, val accuracy 0.643, and val rmse 0.998\n",
      "train loss 0.267, val loss 1.355, val accuracy 0.640, and val rmse 1.003\n",
      "train loss 0.265, val loss 1.385, val accuracy 0.647, and val rmse 1.011\n",
      "train loss 0.257, val loss 1.386, val accuracy 0.640, and val rmse 1.019\n",
      "train loss 0.249, val loss 1.356, val accuracy 0.648, and val rmse 1.005\n",
      "train loss 0.247, val loss 1.359, val accuracy 0.647, and val rmse 1.016\n",
      "train loss 0.236, val loss 1.388, val accuracy 0.648, and val rmse 1.013\n"
     ]
    }
   ],
   "source": [
    "train_model(model_fixed, epochs=50, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = '‡∏°‡∏∑‡∏≠‡∏ñ‡∏∑‡∏≠‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ô‡∏µ‡πâ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏°‡πà‡∏î‡∏µ‡πÄ‡∏•‡∏¢'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = '|'.join(process_text(test_texts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts ,length_test_text = encode_sentence(test_texts,vocab2index )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_loaded.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM_fixed_len(\n",
       "  (embeddings): Embedding(14939, 50, padding_idx=0)\n",
       "  (lstm): LSTM(50, 50, batch_first=True)\n",
       "  (linear): Linear(in_features=50, out_features=5, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_loaded = LSTM_fixed_len(vocab_size, 50, 50)\n",
    "model_loaded.load_state_dict(torch.load(PATH))\n",
    "model_loaded.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loaded = torch.load(PATH)\n",
    "# model_loaded.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_loaded(torch.from_numpy(test_texts.reshape(1,-1)), torch.Tensor([length_test_text]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_pred.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
